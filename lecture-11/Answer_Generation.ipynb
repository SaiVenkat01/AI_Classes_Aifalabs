{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc1a439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b8f5dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "database_name = \"chroma_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab46b469",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/key.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read key from file (or load from env manually)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/key.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create embeddings for the chunks\u001b[39;00m\n",
      "File \u001b[1;32md:\\Visual Studio Code\\AI_Classes_Aifalabs\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/key.txt'"
     ]
    }
   ],
   "source": [
    "# Read key from file (or load from env manually)\n",
    "with open(\"data/key.txt\", \"r\") as f:\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "# Create embeddings for the chunks\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f304d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ No existing vector store found. Please run the indexing script first.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "if os.path.exists(database_name) and os.listdir(database_name):\n",
    "    # Load existing vector store\n",
    "    vectorstore = Chroma(persist_directory=database_name, embedding_function=embedding_model)\n",
    "    print(\"âœ… Loaded existing vector store.\")\n",
    "else:\n",
    "    print(\"âŒ No existing vector store found. Please run the indexing script first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd670f03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho was Lord Rama?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(query, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(retrieved_docs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Result \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;241m.\u001b[39mpage_content[:\u001b[38;5;241m500\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorstore' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"Who was Lord Rama?\"\n",
    "retrieved_docs = vectorstore.similarity_search(query, k=3)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\n--- Result {i+1} ---\\n{doc.page_content[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2852b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a helpful assistant answering questions based on the provided context.\n",
    "\n",
    "### Context Chunks:\n",
    "{context}\n",
    "\n",
    "### Task:\n",
    "Using the context above, answer the user's question **precisely** and **cite the page numbers** you used in square brackets like this: [Page 2], [Page 44].\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3be1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context(chunks):\n",
    "    formatted = \"\"\n",
    "    for doc in chunks:\n",
    "        page = doc.metadata.get(\"page\", \"N/A\")\n",
    "        summary = doc.page_content.strip().split(\"\\n\")[0][:300]\n",
    "        formatted += f\"[Page {page}]: {summary}...\\n\"\n",
    "    return formatted\n",
    "\n",
    "\n",
    "context_block = format_context(retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4be5ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Prompt ---\n",
      " \n",
      "You are a helpful assistant answering questions based on the provided context.\n",
      "\n",
      "### Context Chunks:\n",
      "[Page 2]: 2 ...\n",
      "[Page 44]: 44 ...\n",
      "[Page 44]: contented life in the kingdom and this glorious reign was hailed as ...\n",
      "\n",
      "\n",
      "### Task:\n",
      "Using the context above, answer the user's question **precisely** and **cite the page numbers** you used in square brackets like this: [Page 2], [Page 44].\n",
      "\n",
      "### Question:\n",
      "Who was Lord Rama?\n",
      "\n",
      "### Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=PROMPT_TEMPLATE\n",
    ")\n",
    "final_prompt = prompt.format(context=context_block, question=query)\n",
    "print(\"\\n--- Final Prompt ---\\n\", final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8177310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(\n",
    "    temperature=0.7,\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "response = llm(final_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cfa023",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "## Identity\n",
    "You are an intelligent and friendly AI Appointment Assistant for [COMPANY NAME]. Your primary job is to help users schedule appointments for workshops, demos, or consultations.\n",
    "\n",
    "## Scope\n",
    "- Assist in collecting key appointment information:\n",
    "  - Full Name\n",
    "  - Preferred Date and Time for a quick call\n",
    "  - Email ID\n",
    "  - Phone Number\n",
    "  - Workshop or service details\n",
    "- Provide basic guidance about the scheduling process.\n",
    "- Escalate special requests or unavailable slots to a human agent.\n",
    "\n",
    "## Responsibility\n",
    "- Always start with a warm greeting.\n",
    "- Ask clarifying questions step by step to gather required information.\n",
    "- Offer time slots (if available) or acknowledge user preferences.\n",
    "- Confirm appointment details before finalizing.\n",
    "- Close with a courteous summary and ask if further help is needed.\n",
    "\n",
    "## Chain of Thought (for complex queries)\n",
    "- Break down user intent.\n",
    "- Ask for missing information in a logical sequence.\n",
    "- If user asks for multiple appointments or group bookings, handle each one by confirming details.\n",
    "- If availability is limited, suggest alternative times.\n",
    "\n",
    "## Response Style\n",
    "- Friendly and professional tone.\n",
    "- Short and clear responses.\n",
    "- Bullet or numbered format if multiple steps are explained.\n",
    "- Use polite confirmations: \"Got it\", \"Thanks\", \"Perfect\".\n",
    "\n",
    "## Guardrails\n",
    "- **Privacy**: Do not ask for unnecessary personal information.\n",
    "- **Accuracy**: Only share available slots and service details from the official source.\n",
    "- **Escalation**: If the user has a special case or booking problem, escalate to a human support agent.\n",
    "\n",
    "## Instructions\n",
    "- **Greeting**: Always open with a friendly welcome.\n",
    "  _Example_: \"Hi there! ðŸ‘‹ Iâ€™m here to help you book your appointment. Letâ€™s get started!\"\n",
    "  \n",
    "- **Information Gathering**: Ask for:\n",
    "  1. Full Name  \n",
    "  2. Preferred Date & Time for a quick call  \n",
    "  3. Email ID  \n",
    "  4. Phone Number  \n",
    "  5. Workshop or service details  \n",
    "\n",
    "- **Complex Query Handling**: If a user has multiple queries, handle them sequentially. If unsure, escalate politely.\n",
    "\n",
    "- **Closing**: End the chat with a confirmation.\n",
    "  _Example_: \"Thanks, your appointment is confirmed for [DATE & TIME]. Weâ€™ll contact you at [EMAIL/PHONE]. Is there anything else I can assist you with today?\"\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ“¥ **User Query**:\n",
    "{customer_query}\n",
    "\n",
    "ðŸ¤– **Your Response**:\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
