{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747369390626,
     "user": {
      "displayName": "Dr. Avinash Kumar Singh",
      "userId": "03688237427667000371"
     },
     "user_tz": -330
    },
    "id": "tUgTE6RqUphV",
    "outputId": "74a3a1e2-8ec7-45f5-f86f-0bbf8b24195a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\saive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install and import necessary libraries\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1747369475324,
     "user": {
      "displayName": "Dr. Avinash Kumar Singh",
      "userId": "03688237427667000371"
     },
     "user_tz": -330
    },
    "id": "EyXAfxcJVFr9",
    "outputId": "4b136c8e-41cd-4722-fea4-63b3e10e0764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[alice's adventures in wonderland by lewis carroll 1865]  chapter i. down the rabbit-hole  alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought alice 'without pictures or conversation?'  so she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy an\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load text data\n",
    "raw_text = gutenberg.raw('carroll-alice.txt')\n",
    "raw_text = raw_text.lower().replace('\\n', ' ')\n",
    "\n",
    "print(raw_text[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747369390696,
     "user": {
      "displayName": "Dr. Avinash Kumar Singh",
      "userId": "03688237427667000371"
     },
     "user_tz": -330
    },
    "id": "56AHOWNLVLMf"
   },
   "outputs": [],
   "source": [
    "# Step 3: Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([raw_text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1747369390805,
     "user": {
      "displayName": "Dr. Avinash Kumar Singh",
      "userId": "03688237427667000371"
     },
     "user_tz": -330
    },
    "id": "F3jx5VC3VMay"
   },
   "outputs": [],
   "source": [
    "# Step 4: Create input sequences\n",
    "token_list = tokenizer.texts_to_sequences([raw_text])[0]\n",
    "input_sequences = []\n",
    "sequence_length = 5\n",
    "\n",
    "for i in range(sequence_length, len(token_list)):\n",
    "    input_sequences.append(token_list[i-sequence_length:i+1])\n",
    "\n",
    "input_sequences = np.array(input_sequences)\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24216,
     "status": "ok",
     "timestamp": 1747369463333,
     "user": {
      "displayName": "Dr. Avinash Kumar Singh",
      "userId": "03688237427667000371"
     },
     "user_tz": -330
    },
    "id": "ZDbwogbeVOKl",
    "outputId": "fa3c3cba-8e68-4306-a740-88e0b37f05f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Visual Studio Code\\AI_Classes_Aifalabs\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.0524 - loss: 7.2856\n",
      "Epoch 2/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0609 - loss: 6.0825\n",
      "Epoch 3/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0571 - loss: 5.9786\n",
      "Epoch 4/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.0677 - loss: 5.8674\n",
      "Epoch 5/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.0828 - loss: 5.7434\n",
      "Epoch 6/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.0942 - loss: 5.6277\n",
      "Epoch 7/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.0978 - loss: 5.5282\n",
      "Epoch 8/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.1040 - loss: 5.4222\n",
      "Epoch 9/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.1093 - loss: 5.3380\n",
      "Epoch 10/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.1145 - loss: 5.2525\n",
      "Epoch 11/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.1232 - loss: 5.1483\n",
      "Epoch 12/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.1293 - loss: 5.0319\n",
      "Epoch 13/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.1349 - loss: 4.9567\n",
      "Epoch 14/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.1462 - loss: 4.8560\n",
      "Epoch 15/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.1560 - loss: 4.7676\n",
      "Epoch 16/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.1649 - loss: 4.6554\n",
      "Epoch 17/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.1696 - loss: 4.5805\n",
      "Epoch 18/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.1720 - loss: 4.5257\n",
      "Epoch 19/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.1797 - loss: 4.4277\n",
      "Epoch 20/20\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.1839 - loss: 4.3547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18b5d7026e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Build LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(total_words, 64, input_length=sequence_length),\n",
    "    LSTM(128),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1747369519492,
     "user": {
      "displayName": "Dr. Avinash Kumar Singh",
      "userId": "03688237427667000371"
     },
     "user_tz": -330
    },
    "id": "7pgEd-rwVF3g",
    "outputId": "e3b93584-25e4-4e8b-b03d-57e0d0ae6b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice was beginning to the other thing '\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Prediction function\n",
    "def predict_next_word(seed_text, next_words=1):\n",
    "    for _ in range(next_words):\n",
    "        token_seq = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_seq = pad_sequences([token_seq], maxlen=sequence_length, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_seq, verbose=0), axis=-1)[0]\n",
    "        seed_text += \" \" + tokenizer.index_word[predicted]\n",
    "    return seed_text\n",
    "\n",
    "# Example use\n",
    "print(predict_next_word(\"alice was beginning\", next_words=5))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO9A1xPkeEBG9Vepxw9mlgH",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
